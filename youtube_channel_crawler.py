"""
YouTube ì±„ë„ ì •ë³´ í¬ë¡¤ëŸ¬
YouTube Data API v3ë¥¼ ì‚¬ìš©í•˜ì—¬ ê²€ìƒ‰ì–´ë¡œ ì±„ë„ì„ ì°¾ê³  ì±„ë„ ì •ë³´ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
"""

from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
import json
import os
import re
from datetime import datetime
from dotenv import load_dotenv


class YouTubeChannelCrawler:
    def __init__(self, api_key):
        """
        YouTube Data API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        
        Args:
            api_key (str): YouTube Data API í‚¤
        """
        self.api_key = api_key
        self.youtube = build('youtube', 'v3', developerKey=api_key)
    
    @staticmethod
    def load_existing_data(filename='youtube_channels.json'):
        """
        ê¸°ì¡´ JSON íŒŒì¼ì—ì„œ ì±„ë„ ë°ì´í„° ë¡œë“œ
        
        Args:
            filename (str): JSON íŒŒì¼ëª…
        
        Returns:
            dict: {channel_id: channel_data} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
        """
        if not os.path.exists(filename):
            print(f"â„¹ï¸  ê¸°ì¡´ íŒŒì¼ ì—†ìŒ - ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤")
            return {}
        
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # channel_idë¥¼ í‚¤ë¡œ í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
            existing = {item['channel_id']: item for item in data}
            print(f"âœ“ ê¸°ì¡´ ë°ì´í„° ë¡œë“œ: {len(existing)}ê°œ ì±„ë„")
            return existing
            
        except Exception as e:
            print(f"âš ï¸  ê¸°ì¡´ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    @staticmethod
    def make_safe_filename(query):
        """
        ê²€ìƒ‰ì–´ë¥¼ ì•ˆì „í•œ íŒŒì¼ëª…ìœ¼ë¡œ ë³€í™˜
        
        Args:
            query (str): ê²€ìƒ‰ì–´
        
        Returns:
            str: ì•ˆì „í•œ íŒŒì¼ëª…
        """
        # íŒŒì¼ëª…ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ì ì œê±°
        safe_query = re.sub(r'[<>:"/\\|?*]', '', query)
        # ê³µë°±ì„ ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ë³€í™˜
        safe_query = safe_query.replace(' ', '_')
        # ìµœëŒ€ 50ìë¡œ ì œí•œ
        safe_query = safe_query[:50]
        
        return f"youtube_channels_{safe_query}.json"
    
    @staticmethod
    def extract_email(text):
        """
        í…ìŠ¤íŠ¸ì—ì„œ ì´ë©”ì¼ ì£¼ì†Œ ì¶”ì¶œ
        
        Args:
            text (str): ê²€ìƒ‰í•  í…ìŠ¤íŠ¸
        
        Returns:
            str: ì°¾ì€ ì´ë©”ì¼ ì£¼ì†Œ ë˜ëŠ” ë¹ˆ ë¬¸ìì—´
        """
        if not text:
            return ''
        
        # ì´ë©”ì¼ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´
        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        
        # ì´ë©”ì¼ ì°¾ê¸°
        emails = re.findall(email_pattern, text)
        
        # ì²« ë²ˆì§¸ ì´ë©”ì¼ ë°˜í™˜ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
        return emails[0] if emails else ''
    
    @staticmethod
    def is_korean_text(text):
        """
        í…ìŠ¤íŠ¸ì— í•œêµ­ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        
        Args:
            text (str): ê²€ìƒ‰í•  í…ìŠ¤íŠ¸
        
        Returns:
            bool: í•œêµ­ì–´ í¬í•¨ ì—¬ë¶€
        """
        if not text:
            return False
        
        # í•œê¸€ ìœ ë‹ˆì½”ë“œ ë²”ìœ„: AC00-D7A3
        korean_pattern = re.compile('[ê°€-í£]+')
        
        # í•œê¸€ì´ ìˆëŠ”ì§€ í™•ì¸
        return bool(korean_pattern.search(text))
    
    @staticmethod
    def extract_contact_info(text):
        """
        í…ìŠ¤íŠ¸ì—ì„œ ë‹¤ì–‘í•œ ì—°ë½ì²˜ ì •ë³´ ì¶”ì¶œ
        
        Args:
            text (str): ê²€ìƒ‰í•  í…ìŠ¤íŠ¸
        
        Returns:
            dict: ì¶”ì¶œëœ ì—°ë½ì²˜ ì •ë³´
        """
        if not text:
            return {
                'email': '',
                'phone': '',
                'kakao': '',
                'other_links': []
            }
        
        contact_info = {
            'email': '',
            'phone': '',
            'kakao': '',
            'other_links': []
        }
        
        # ì´ë©”ì¼
        email_pattern = r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}'
        emails = re.findall(email_pattern, text)
        if emails:
            contact_info['email'] = emails[0]
        
        # ì „í™”ë²ˆí˜¸ (í•œêµ­)
        phone_patterns = [
            r'010[-\s]?\d{4}[-\s]?\d{4}',
            r'01[016789][-\s]?\d{3,4}[-\s]?\d{4}',
            r'\+82[-\s]?10[-\s]?\d{4}[-\s]?\d{4}'
        ]
        for pattern in phone_patterns:
            matches = re.findall(pattern, text)
            if matches:
                contact_info['phone'] = matches[0]
                break
        
        # ì¹´ì¹´ì˜¤í†¡ ID
        kakao_patterns = [
            r'ì¹´ì¹´ì˜¤[í†¡]?[:\s]+([a-zA-Z0-9_-]+)',
            r'kakao[talk]?[:\s]+([a-zA-Z0-9_-]+)',
        ]
        for pattern in kakao_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            if matches:
                contact_info['kakao'] = matches[0]
                break
        
        # ê¸°íƒ€ ì—°ë½ ë°©ë²• (ë„¤ì´ë²„ ë¸”ë¡œê·¸, ê°œì¸ ì‚¬ì´íŠ¸ ë“±)
        url_pattern = r'https?://[^\s<>"\)]+|www\.[^\s<>"\)]+'
        urls = re.findall(url_pattern, text)
        # ìœ íŠœë¸Œ, ì†Œì…œë¯¸ë””ì–´ ë§í¬ ì œì™¸í•˜ê³  ê°œì¸ ì—°ë½ ë§í¬ë§Œ
        contact_urls = []
        exclude_domains = ['youtube.com', 'youtu.be', 'instagram.com', 'twitter.com', 'facebook.com', 'x.com']
        for url in urls:
            if not any(domain in url.lower() for domain in exclude_domains):
                contact_urls.append(url)
        
        contact_info['other_links'] = contact_urls[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€
        
        return contact_info
    
    def search_channels(self, query, max_results=10, order='relevance', page_token=None):
        """
        ê²€ìƒ‰ì–´ë¡œ ì±„ë„ ê²€ìƒ‰
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            max_results (int): ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸ê°’: 10)
            order (str): ì •ë ¬ ë°©ì‹ - 'relevance'(ê´€ë ¨ì„±), 'date'(ìµœì‹ ìˆœ), 'viewCount'(ì¡°íšŒìˆ˜ìˆœ)
            page_token (str): ë‹¤ìŒ í˜ì´ì§€ í† í° (í˜ì´ì§€ë„¤ì´ì…˜ìš©)
        
        Returns:
            tuple: (channels ë¦¬ìŠ¤íŠ¸, next_page_token)
        """
        try:
            # ì±„ë„ íƒ€ì…ë§Œ ê²€ìƒ‰
            search_params = {
                'q': query,
                'type': 'channel',
                'part': 'id,snippet',
                'maxResults': max_results,
                'order': order
            }
            
            if page_token:
                search_params['pageToken'] = page_token
            
            search_response = self.youtube.search().list(**search_params).execute()
            
            channels = []
            for item in search_response.get('items', []):
                channel_id = item['id']['channelId']
                channel_title = item['snippet']['title']
                channels.append({
                    'channel_id': channel_id,
                    'title': channel_title,
                    'description': item['snippet']['description']
                })
            
            next_page_token = search_response.get('nextPageToken')
            
            order_text = {
                'relevance': 'ê´€ë ¨ì„±ìˆœ',
                'date': 'ìµœì‹ ìˆœ',
                'viewCount': 'ì¡°íšŒìˆ˜ìˆœ'
            }.get(order, order)
            
            page_info = f" (ì¶”ê°€ í˜ì´ì§€)" if page_token else ""
            print(f"âœ“ ê²€ìƒ‰ì–´ '{query}'ë¡œ {len(channels)}ê°œ ì±„ë„ ë°œê²¬ ({order_text}){page_info}")
            
            return channels, next_page_token
            
        except HttpError as e:
            print(f"âœ— API ì˜¤ë¥˜ ë°œìƒ: {e}")
            return [], None
    
    def get_channel_details(self, channel_id):
        """
        ì±„ë„ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            channel_id (str): ì±„ë„ ID
        
        Returns:
            dict: ì±„ë„ ìƒì„¸ ì •ë³´
        """
        try:
            # ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            channel_response = self.youtube.channels().list(
                part='snippet,statistics,contentDetails,brandingSettings',
                id=channel_id
            ).execute()
            
            if not channel_response.get('items'):
                return None
            
            channel = channel_response['items'][0]
            
            # ì±„ë„ ì •ë³´ ì¶”ì¶œ
            snippet = channel['snippet']
            statistics = channel.get('statistics', {})
            branding = channel.get('brandingSettings', {})
            description = snippet.get('description', '')
            
            # ì—°ë½ì²˜ ì •ë³´ ì¶”ì¶œ
            contact_info = self.extract_contact_info(description)
            
            # í•œêµ­ì–´ ì—¬ë¶€ í™•ì¸
            is_korean = (
                snippet.get('country') == 'KR' or 
                self.is_korean_text(description) or 
                self.is_korean_text(snippet['title'])
            )
            
            channel_info = {
                'channel_id': channel_id,
                'title': snippet['title'],
                'description': description,
                'custom_url': snippet.get('customUrl', ''),
                'published_at': snippet['publishedAt'],
                'country': snippet.get('country', 'N/A'),
                'is_korean': is_korean,
                
                # í†µê³„
                'subscriber_count': statistics.get('subscriberCount', 'N/A'),
                'video_count': statistics.get('videoCount', 'N/A'),
                'view_count': statistics.get('viewCount', 'N/A'),
                
                # ë§í¬
                'channel_url': f"https://www.youtube.com/channel/{channel_id}",
                'custom_channel_url': f"https://www.youtube.com/{snippet.get('customUrl', '')}" if snippet.get('customUrl') else '',
                
                # ì—°ë½ì²˜ ì •ë³´ (ì´ë©”ì¼, ì „í™”, ì¹´ì¹´ì˜¤, ê¸°íƒ€ ë§í¬ë§Œ)
                'email': contact_info['email'] if contact_info['email'] else 'N/A',
                'phone': contact_info['phone'] if contact_info['phone'] else 'N/A',
                'kakao': contact_info['kakao'] if contact_info['kakao'] else 'N/A',
                'other_links': ', '.join(contact_info['other_links']) if contact_info['other_links'] else 'N/A',
                
                # ì—°ë½ ê°€ëŠ¥ ì—¬ë¶€
                'contactable': any([
                    contact_info['email'],
                    contact_info['phone'],
                    contact_info['kakao'],
                    contact_info['other_links']
                ]),
                
                # ì¸ë„¤ì¼
                'thumbnail': snippet.get('thumbnails', {}).get('high', {}).get('url', ''),
            }
            
            return channel_info
            
        except HttpError as e:
            print(f"âœ— ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨ ({channel_id}): {e}")
            return None
    
    def crawl(self, query, max_results=10, korean_only=True, order='relevance', 
              data_file=None, update_mode=True, contactable_only=True):
        """
        ê²€ìƒ‰ì–´ë¡œ ì±„ë„ì„ ê²€ìƒ‰í•˜ê³  ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        
        Args:
            query (str): ê²€ìƒ‰ì–´
            max_results (int): ëª©í‘œ ìˆ˜ì§‘ ê°œìˆ˜ (ì¤‘ë³µ/í•„í„°ë§ ì œì™¸ í›„)
            korean_only (bool): í•œêµ­ ì±„ë„ë§Œ í•„í„°ë§ (ê¸°ë³¸ê°’: True)
            order (str): ì •ë ¬ ë°©ì‹ - 'relevance'(ê´€ë ¨ì„±), 'date'(ìµœì‹ ìˆœ), 'viewCount'(ì¡°íšŒìˆ˜ìˆœ)
            data_file (str): ë°ì´í„°ë¥¼ ì €ì¥/ë¡œë“œí•  JSON íŒŒì¼ëª… (Noneì´ë©´ ê²€ìƒ‰ì–´ë¡œ ìë™ ìƒì„±)
            update_mode (bool): Trueë©´ ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€, Falseë©´ ìƒˆë¡œ ìƒì„±
            contactable_only (bool): Trueë©´ ì—°ë½ì²˜ ìˆëŠ” ì±„ë„ë§Œ ìˆ˜ì§‘ (ê¸°ë³¸ê°’: True)
        
        Returns:
            tuple: (channels ë¦¬ìŠ¤íŠ¸, ì‚¬ìš©ëœ íŒŒì¼ëª…)
        """
        # íŒŒì¼ëª… ìë™ ìƒì„± (ì§€ì •í•˜ì§€ ì•Šì€ ê²½ìš°)
        if data_file is None:
            data_file = self.make_safe_filename(query)
        
        print(f"\n{'='*60}")
        print(f"YouTube ì±„ë„ í¬ë¡¤ë§ ì‹œì‘: '{query}'")
        print(f"ğŸ’¾ ì €ì¥ íŒŒì¼: {data_file}")
        print(f"ğŸ¯ ëª©í‘œ: ìƒˆ ì±„ë„ {max_results}ê°œ ìˆ˜ì§‘")
        if korean_only:
            print("ğŸ‡°ğŸ‡· í•œêµ­ ì±„ë„ë§Œ í•„í„°ë§")
        if contactable_only:
            print("ğŸ“§ ì—°ë½ì²˜ ìˆëŠ” ì±„ë„ë§Œ ìˆ˜ì§‘")
        
        order_text = {
            'relevance': 'ê´€ë ¨ì„±ìˆœ',
            'date': 'ìµœì‹ ìˆœ',
            'viewCount': 'ì¡°íšŒìˆ˜ìˆœ'
        }.get(order, order)
        print(f"ğŸ“Š ì •ë ¬: {order_text}")
        print(f"{'='*60}\n")
        
        # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (update_modeì¼ ë•Œë§Œ)
        existing_data = {}
        if update_mode:
            existing_data = self.load_existing_data(data_file)
        
        # ìˆ˜ì§‘ ë³€ìˆ˜
        new_channels = []
        duplicate_count = 0
        filtered_count = 0
        no_contact_count = 0  # ì—°ë½ì²˜ ì—†ìŒ ì¹´ìš´íŠ¸
        page_token = None
        search_count = 0
        max_search_attempts = 10  # ìµœëŒ€ 10ë²ˆê¹Œì§€ ì¶”ê°€ ê²€ìƒ‰
        
        # ëª©í‘œ ê°œìˆ˜ë¥¼ ì±„ìš¸ ë•Œê¹Œì§€ ë°˜ë³µ ê²€ìƒ‰
        while len(new_channels) < max_results and search_count < max_search_attempts:
            search_count += 1
            
            # ë¶€ì¡±í•œ ê°œìˆ˜ ê³„ì‚° (ì—¬ìœ ìˆê²Œ 2ë°° ê²€ìƒ‰)
            needed = (max_results - len(new_channels)) * 2
            search_size = min(needed, 50)  # API ì œí•œ: ìµœëŒ€ 50ê°œ
            
            if search_count > 1:
                print(f"\n{'='*60}")
                print(f"ğŸ“ ë¶€ì¡±ë¶„ ì¶”ê°€ ê²€ìƒ‰ ({search_count}íšŒì°¨)")
                print(f"   í˜„ì¬: {len(new_channels)}ê°œ, ëª©í‘œ: {max_results}ê°œ")
                print(f"   ì¶”ê°€ ê²€ìƒ‰: {search_size}ê°œ")
                print(f"{'='*60}\n")
            
            # ì±„ë„ ê²€ìƒ‰
            channels, next_page_token = self.search_channels(
                query, 
                max_results=search_size, 
                order=order, 
                page_token=page_token
            )
            
            if not channels:
                print("ë” ì´ìƒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
            
            # ë‹¤ìŒ í˜ì´ì§€ í† í° ì €ì¥
            page_token = next_page_token
            
            # ê° ì±„ë„ì˜ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
            for i, channel in enumerate(channels, 1):
                # ì´ë¯¸ ëª©í‘œ ê°œìˆ˜ë¥¼ ë‹¬ì„±í–ˆìœ¼ë©´ ì¤‘ë‹¨
                if len(new_channels) >= max_results:
                    print(f"\nâœ… ëª©í‘œ ê°œìˆ˜ ë‹¬ì„±! ({len(new_channels)}ê°œ)")
                    break
                
                channel_id = channel['channel_id']
                
                # ì¤‘ë³µ ì²´í¬
                if channel_id in existing_data:
                    print(f"\n[ê²€ìƒ‰ {search_count}íšŒ-{i}/{len(channels)}] {channel['title']}")
                    print(f"  âŠ ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì±„ë„ - ê±´ë„ˆëœ€")
                    duplicate_count += 1
                    continue
                
                print(f"\n[ê²€ìƒ‰ {search_count}íšŒ-{i}/{len(channels)}] {channel['title']} ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
                
                details = self.get_channel_details(channel_id)
                if details:
                    # í•œêµ­ ì±„ë„ í•„í„°ë§
                    if korean_only and not details['is_korean']:
                        print(f"  âŠ í•œêµ­ ì±„ë„ ì•„ë‹˜ - ì œì™¸")
                        filtered_count += 1
                        continue
                    
                    # ì—°ë½ì²˜ í•„í„°ë§
                    if contactable_only and not details['contactable']:
                        print(f"  âŠ ì—°ë½ì²˜ ì—†ìŒ - ì œì™¸")
                        no_contact_count += 1
                        continue
                    
                    new_channels.append(details)
                    
                    # ì—°ë½ì²˜ ì •ë³´ ì¶œë ¥
                    contact_methods = []
                    if details['email'] != 'N/A':
                        contact_methods.append(f"ì´ë©”ì¼: {details['email']}")
                    if details['phone'] != 'N/A':
                        contact_methods.append(f"ì „í™”: {details['phone']}")
                    if details['kakao'] != 'N/A':
                        contact_methods.append(f"ì¹´í†¡: {details['kakao']}")
                    if details['other_links'] != 'N/A':
                        contact_methods.append(f"ë§í¬: {details['other_links'][:50]}...")
                    
                    print(f"  âœ“ êµ¬ë…ì: {details['subscriber_count']}, ë™ì˜ìƒ: {details['video_count']}")
                    print(f"  âœ“ ì§„í–‰: {len(new_channels)}/{max_results}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
                    if contact_methods:
                        print(f"  ğŸ“§ ì—°ë½ì²˜: {', '.join(contact_methods)}")
                    else:
                        print(f"  âš ï¸  ì—°ë½ì²˜ ì •ë³´ ì—†ìŒ")
            
            # ë‹¤ìŒ í˜ì´ì§€ê°€ ì—†ìœ¼ë©´ ì¤‘ë‹¨
            if not page_token:
                print("\nâš ï¸  ë” ì´ìƒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                break
        
        # ìµœì¢… ê²°ê³¼
        print(f"\n{'='*60}")
        if duplicate_count > 0:
            print(f"â„¹ï¸  ì¤‘ë³µ ì±„ë„ ì œì™¸: {duplicate_count}ê°œ")
        if korean_only and filtered_count > 0:
            print(f"â„¹ï¸  í•œêµ­ ì±„ë„ ì•„ë‹˜ìœ¼ë¡œ ì œì™¸: {filtered_count}ê°œ")
        if contactable_only and no_contact_count > 0:
            print(f"â„¹ï¸  ì—°ë½ì²˜ ì—†ìŒìœ¼ë¡œ ì œì™¸: {no_contact_count}ê°œ")
        
        # ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆ ë°ì´í„° ë³‘í•©
        all_channels = list(existing_data.values()) + new_channels
        
        print(f"âœ“ ìƒˆë¡œ ì¶”ê°€ëœ ì±„ë„: {len(new_channels)}ê°œ")
        if len(new_channels) < max_results:
            print(f"âš ï¸  ëª©í‘œ({max_results}ê°œ)ì— ë¯¸ë‹¬í–ˆìŠµë‹ˆë‹¤. (ë¶€ì¡±: {max_results - len(new_channels)}ê°œ)")
        print(f"âœ“ ì „ì²´ ì±„ë„: {len(all_channels)}ê°œ")
        
        # ì—°ë½ ê°€ëŠ¥ ì±„ë„ í†µê³„ (ëª¨ë‘ ì—°ë½ ê°€ëŠ¥í•˜ë¯€ë¡œ 100%)
        contactable_count = sum(1 for ch in all_channels if ch['contactable'])
        if contactable_only:
            print(f"ğŸ“§ ì—°ë½ ê°€ëŠ¥ ì±„ë„: {contactable_count}/{len(all_channels)}ê°œ (100%)")
        else:
            print(f"ğŸ“§ ì—°ë½ ê°€ëŠ¥ ì±„ë„: {contactable_count}/{len(all_channels)}ê°œ")
        print(f"{'='*60}\n")
        
        return all_channels, data_file
    
    def save_to_json(self, channels, filename='youtube_channels.json'):
        """
        ì±„ë„ ì •ë³´ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
        
        Args:
            channels (list): ì±„ë„ ì •ë³´ ë¦¬ìŠ¤íŠ¸
            filename (str): íŒŒì¼ëª…
        """
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(channels, f, ensure_ascii=False, indent=2)
        print(f"âœ“ JSON íŒŒì¼ ì €ì¥: {filename}")


def main():
    """
    í‚¤ì›Œë“œ íŒŒì¼ ê¸°ë°˜ ìë™ ìˆ˜ì§‘
    """
    # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    
    # í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
    API_KEY = os.getenv('YOUTUBE_API_KEY')
    
    if not API_KEY or API_KEY == 'YOUR_ACTUAL_API_KEY_HERE':
        print("âš ï¸  ì˜¤ë¥˜: API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("ğŸ“ .env íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:")
        print("   YOUTUBE_API_KEY=your_actual_api_key_here")
        print("\nğŸ’¡ API í‚¤ ë°œê¸‰ ë°©ë²•ì€ README.mdë¥¼ ì°¸ê³ í•˜ì„¸ìš”.")
        return
    
    # í‚¤ì›Œë“œ íŒŒì¼ ê²½ë¡œ
    KEYWORDS_FILE = 'keywords.txt'
    
    # í‚¤ì›Œë“œ íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(KEYWORDS_FILE):
        print(f"âš ï¸  ì˜¤ë¥˜: {KEYWORDS_FILE} íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
        print("\nğŸ“ keywords.txt íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒê³¼ ê°™ì´ í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:")
        print("   (í•œ ì¤„ì— í•˜ë‚˜ì”©)")
        print("\nì˜ˆì‹œ:")
        print("   íŒŒì´ì¬")
        print("   ìš”ë¦¬")
        print("   ê²Œì„")
        print("   ì˜ì–´ê³µë¶€")
        print("\níŒŒì¼ì„ ìƒì„±í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
        
        # ì˜ˆì‹œ íŒŒì¼ ìë™ ìƒì„±
        try:
            with open(KEYWORDS_FILE, 'w', encoding='utf-8') as f:
                f.write("íŒŒì´ì¬\nìš”ë¦¬\nê²Œì„\n")
            print(f"\nâœ… ì˜ˆì‹œ íŒŒì¼({KEYWORDS_FILE})ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤!")
            print("   íŒŒì¼ì„ ìˆ˜ì •í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
        except Exception as e:
            print(f"\nâŒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        
        return
    
    # í‚¤ì›Œë“œ íŒŒì¼ ì½ê¸°
    try:
        with open(KEYWORDS_FILE, 'r', encoding='utf-8') as f:
            keywords = [line.strip() for line in f if line.strip()]
        
        if not keywords:
            print(f"âš ï¸  ì˜¤ë¥˜: {KEYWORDS_FILE} íŒŒì¼ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            print("í‚¤ì›Œë“œë¥¼ ì…ë ¥í•œ í›„ ë‹¤ì‹œ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
            
    except Exception as e:
        print(f"âš ï¸  íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        return
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = YouTubeChannelCrawler(API_KEY)
    
    # ì„¤ì •
    MAX_RESULTS_PER_KEYWORD = 50  # í‚¤ì›Œë“œë‹¹ 50ê°œ
    KOREAN_ONLY = True
    ORDER = 'relevance'  # ê´€ë ¨ì„±ìˆœ
    CONTACTABLE_ONLY = True  # ì—°ë½ì²˜ ìˆëŠ” ê²ƒë§Œ
    
    print("="*60)
    print("ğŸ¯ YouTube ì±„ë„ ìë™ ìˆ˜ì§‘ ì‹œì‘")
    print("="*60)
    print(f"ğŸ“‹ í‚¤ì›Œë“œ íŒŒì¼: {KEYWORDS_FILE}")
    print(f"ğŸ“Š ì´ í‚¤ì›Œë“œ ìˆ˜: {len(keywords)}ê°œ")
    print(f"ğŸ¯ í‚¤ì›Œë“œë‹¹ ëª©í‘œ: {MAX_RESULTS_PER_KEYWORD}ê°œ")
    print(f"ğŸ‡°ğŸ‡· í•œêµ­ ì±„ë„ë§Œ: {'ì˜ˆ' if KOREAN_ONLY else 'ì•„ë‹ˆì˜¤'}")
    print(f"ğŸ“§ ì—°ë½ì²˜ í•„ìˆ˜: {'ì˜ˆ' if CONTACTABLE_ONLY else 'ì•„ë‹ˆì˜¤'}")
    print(f"ğŸ“Š ì •ë ¬: ìµœì‹ ìˆœ")
    print("="*60)
    print("\ní‚¤ì›Œë“œ ëª©ë¡:")
    for i, keyword in enumerate(keywords, 1):
        print(f"  {i}. {keyword}")
    print("\n" + "="*60)
    
    input("\nê³„ì†í•˜ë ¤ë©´ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”... (Ctrl+Cë¡œ ì·¨ì†Œ)")
    
    # ì „ì²´ ìˆ˜ì§‘ í†µê³„
    total_collected = 0
    total_failed = 0
    results_summary = []
    
    # ê° í‚¤ì›Œë“œë³„ë¡œ ìˆ˜ì§‘
    for idx, keyword in enumerate(keywords, 1):
        print(f"\n\n{'#'*60}")
        print(f"# ì§„í–‰: {idx}/{len(keywords)} - '{keyword}'")
        print(f"{'#'*60}\n")
        
        try:
            # ì±„ë„ ì •ë³´ í¬ë¡¤ë§
            channels, data_file = crawler.crawl(
                keyword,
                max_results=MAX_RESULTS_PER_KEYWORD,
                korean_only=KOREAN_ONLY,
                order=ORDER,
                data_file=None,  # ìë™ ìƒì„±
                update_mode=True,
                contactable_only=CONTACTABLE_ONLY
            )
            
            # JSON íŒŒì¼ë¡œ ì €ì¥
            crawler.save_to_json(channels, data_file)
            
            # ìƒˆë¡œ ì¶”ê°€ëœ ì±„ë„ ìˆ˜ ê³„ì‚° (ì „ì²´ì—ì„œ ê¸°ì¡´ ë°ì´í„° ì œì™¸)
            new_count = len([ch for ch in channels if ch.get('channel_id')])
            
            # í†µê³„ ì €ì¥
            result = {
                'keyword': keyword,
                'file': data_file,
                'total': len(channels),
                'new': new_count,
                'contactable': sum(1 for ch in channels if ch.get('contactable'))
            }
            results_summary.append(result)
            total_collected += new_count
            
            print(f"\nâœ… '{keyword}' ì™„ë£Œ!")
            print(f"   íŒŒì¼: {data_file}")
            print(f"   ìˆ˜ì§‘: {len(channels)}ê°œ (ì „ì²´)")
            
        except Exception as e:
            print(f"\nâŒ '{keyword}' ì‹¤íŒ¨: {e}")
            total_failed += 1
            results_summary.append({
                'keyword': keyword,
                'file': None,
                'total': 0,
                'new': 0,
                'contactable': 0,
                'error': str(e)
            })
        
        # ë§ˆì§€ë§‰ í‚¤ì›Œë“œê°€ ì•„ë‹ˆë©´ ì ì‹œ ëŒ€ê¸°
        if idx < len(keywords):
            print(f"\nâ³ ë‹¤ìŒ í‚¤ì›Œë“œë¡œ ì´ë™... (ì ì‹œ ëŒ€ê¸°)")
            import time
            time.sleep(2)
    
    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    print("\n\n" + "="*60)
    print("ğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
    print("="*60)
    print(f"\nğŸ“Š ìµœì¢… í†µê³„:")
    print(f"   ì²˜ë¦¬í•œ í‚¤ì›Œë“œ: {len(keywords)}ê°œ")
    print(f"   ì„±ê³µ: {len(keywords) - total_failed}ê°œ")
    print(f"   ì‹¤íŒ¨: {total_failed}ê°œ")
    
    print(f"\nğŸ“‹ í‚¤ì›Œë“œë³„ ê²°ê³¼:")
    print("-" * 60)
    for i, result in enumerate(results_summary, 1):
        if 'error' in result:
            print(f"{i:2d}. {result['keyword']:20s} - âŒ ì‹¤íŒ¨")
        else:
            print(f"{i:2d}. {result['keyword']:20s} - âœ… {result['total']:3d}ê°œ ì±„ë„")
            print(f"    â””â”€ íŒŒì¼: {result['file']}")
    
    print("\n" + "="*60)
    print("ğŸ’¾ ìƒì„±ëœ íŒŒì¼ë“¤:")
    print("-" * 60)
    for result in results_summary:
        if result['file']:
            print(f"   â€¢ {result['file']}")
    
    print("\nâœ¨ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
    print("="*60)


if __name__ == '__main__':
    main()